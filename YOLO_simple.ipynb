{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YOLO_simple.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN28Xat4cD6a2O6nZ6kK/Yy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"--9303_aCjPm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625613123213,"user_tz":240,"elapsed":34852,"user":{"displayName":"kiki sarpong","photoUrl":"","userId":"05139323076200161800"}},"outputId":"8e719732-8709-4d0d-8e59-8c562ab8c57f"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)   #link to google drive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fMXTTSFaDbew","executionInfo":{"status":"ok","timestamp":1625613127045,"user_tz":240,"elapsed":1400,"user":{"displayName":"kiki sarpong","photoUrl":"","userId":"05139323076200161800"}},"outputId":"258c6b19-1794-4636-d4a9-76923384a5ab"},"source":["os.chdir(\"/content/drive/My Drive/perception projects/object tracking\")  #change directory to directory with needed files for YOLO tracking\n","!ls      #print out files in directory"],"execution_count":null,"outputs":[{"output_type":"stream","text":["images\tmovie.mp4  YOLO_simple.ipynb  yolo_Starter.ipynb  yolov3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4L94vHOtEWzq","executionInfo":{"status":"ok","timestamp":1625614876871,"user_tz":240,"elapsed":4079,"user":{"displayName":"kiki sarpong","photoUrl":"","userId":"05139323076200161800"}},"outputId":"ec9cac31-5ed1-4da0-8c94-d64e96e7e6ca"},"source":["!python3 -m pip install yolov4==2.0.2 # After Checking, YOLO 2.0.2 works without modifying anything. Otherwise keep 1.2.1from yolov4.tf import YOLOv4\n","from yolov4.tf import YOLOv4\n","import tensorflow as tf\n","import time\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: yolov4==2.0.2 in /usr/local/lib/python3.7/dist-packages (2.0.2)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from yolov4==2.0.2) (1.9)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from yolov4==2.0.2) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b2YsXV6jEW6W"},"source":["yolo = YOLOv4(tiny=False)\n","yolo.classes = \"Yolov4/coco.names\"\n","yolo.make_model()\n","yolo.load_weights(\"Yolov4/yolov4.weights\", weights_type=\"yolo\")\n","\n","def run_obstacle_detection(img):\n","    start_time=time.time()\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    resized_image = yolo.resize_image(img)\n","\n","    # 0 ~ 255 to 0.0 ~ 1.0\n","    resized_image = resized_image / 255.      #normalize image\n","\n","    #input_data == Dim(1, input_size, input_size, channels)\n","    input_data = resized_image[np.newaxis, ...].astype(np.float32)  #add one more dimension to image structure and change data type\n","    candidates = yolo.model.predict(input_data)   #model predict\n","\n","    _candidates = []\n","    result = img.copy()     #create a copy of the image\n","    for candidate in candidates:\n","        batch_size = candidate.shape[0]\n","        grid_size = candidate.shape[1]\n","        _candidates.append(tf.reshape(candidate, shape=(1, grid_size * grid_size * 3, -1)))   #reshape candidate\n","\n","        #candidates == Dim(batch, candidates, (bbox))\n","        candidates = np.concatenate(_candidates, axis=1)\n","        \n","        #pred_bboxes == Dim(candidates, (x, y, w, h, class_id, prob))\n","        pred_bboxes = yolo.candidates_to_pred_bboxes(candidates[0], iou_threshold=0.35, score_threshold=0.40)\n","        pred_bboxes = pred_bboxes[~(pred_bboxes==0).all(1)] #https://stackoverflow.com/questions/35673095/python-how-to-eliminate-all-the-zero-rows-from-a-matrix-in-numpy?lq=1\n","        pred_bboxes = yolo.fit_pred_bboxes_to_original(pred_bboxes, img.shape)\n","        exec_time = time.time() - start_time\n","        #print(\"time: {:.2f} ms\".format(exec_time * 1000))\n","        result = yolo.draw_bboxes(img, pred_bboxes)\n","        result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n","    return result, pred_bboxes\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1AfATKcDgZO6tjDXIbw-UVJqHKunQ_6YT"},"id":"QR4_dPTWKQq2","executionInfo":{"status":"ok","timestamp":1625617250545,"user_tz":240,"elapsed":15458,"user":{"displayName":"kiki sarpong","photoUrl":"","userId":"05139323076200161800"}},"outputId":"d59de690-dade-4682-9e99-80a43658bc9b"},"source":["import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimp\n","import numpy as npc \n","!pwd\n","path = \"images/man_bike.jpg\"\n","image = mpimg.imread(path)\n","plt.imshow(image)\n","\n","result, pred_bboxes = run_obstacle_detection(image)\n","fig_camera = plt.figure(figsize=(20, 20))\n","ax_lidar = fig_camera.subplots()\n","ax_lidar.imshow(result)\n","plt.show()\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"HBcl8zBfT_uI"},"source":["from moviepy.editor import VideoFileClip\n","video_file = \"images/day_drive_2mins.mp4\"\n","clip = VideoFileClip(video_file).subclip(0,50)\n","white_clip = clip.fl_image(run_obstacle_detection)\n","%time white_clip.write_videofile(\"output_daydrive.mp4\",audio=False)"],"execution_count":null,"outputs":[]}]}